{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# A bit of setup\n",
    "import numpy as np\n",
    "import copy\n",
    "import random as rnd\n",
    "from sets import Set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((3,3))\n",
    "np.fliplr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Board:\n",
    "    '''\n",
    "    state is n x n ndarray, 0: unknown, 1: X (first), -1: O (later)\n",
    "    '''\n",
    "    def __init__(self, size=3):\n",
    "        self.reset(size)\n",
    "            \n",
    "    def reset(self, size=3):\n",
    "        self.size = size\n",
    "        self.state = np.zeros( (self.size, self.size) ) # board state\n",
    "        self.unassigned = Set()  # available position tuples\n",
    "        it = np.nditer(self.state, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            ix = it.multi_index  # e.g., (1, 2)\n",
    "            self.unassigned.add( ix )\n",
    "            it.iternext()\n",
    "\n",
    "            \n",
    "    def print_board(self):\n",
    "        print '------------------'\n",
    "        for x in xrange( self.size ):\n",
    "            for y in xrange( self.size ):\n",
    "                if self.state[x, y] == 1:\n",
    "                    print 'X\\t',\n",
    "                elif self.state[x, y] == -1:\n",
    "                    print 'O\\t',\n",
    "                else:\n",
    "                    print '()\\t',\n",
    "            print\n",
    "        print '------------------'\n",
    "        \n",
    "    # x: up-down, y: left-right    \n",
    "    def add_X(self, x, y): \n",
    "        self.state[x, y] = 1\n",
    "        self.unassigned.remove( (x, y) )\n",
    "    \n",
    "    def add_O(self, x, y):\n",
    "        self.state[x, y] = -1\n",
    "        self.unassigned.remove( (x, y) )\n",
    "\n",
    "    # clear a position to be unassigned\n",
    "    def clear_pos(self, x, y):\n",
    "        self.state[x, y] = 0\n",
    "        self.unassigned.add( (x, y) )\n",
    "\n",
    "    \n",
    "    # 0: ongoing, 1: agent (first) wins, -1: agent (later) wins,  2: draw  (game over, !=0)\n",
    "    def if_win(self):\n",
    "        if self.state[:, 0].sum() == 3 \\\n",
    "        or self.state[:, 1].sum() == 3 \\\n",
    "        or self.state[:, 2].sum() == 3 \\\n",
    "        or self.state[0, :].sum() == 3 \\\n",
    "        or self.state[1, :].sum() == 3 \\\n",
    "        or self.state[2, :].sum() == 3 \\\n",
    "        or self.state.diagonal().sum() == 3\\\n",
    "        or np.fliplr(self.state).diagonal().sum() == 3:\n",
    "            return 1\n",
    "        elif self.state[:, 0].sum() == -3 \\\n",
    "        or self.state[:, 1].sum() == -3 \\\n",
    "        or self.state[:, 2].sum() == -3 \\\n",
    "        or self.state[0, :].sum() == -3 \\\n",
    "        or self.state[1, :].sum() == -3 \\\n",
    "        or self.state[2, :].sum() == -3 \\\n",
    "        or self.state.diagonal().sum() == -3 \\\n",
    "        or np.fliplr(self.state).diagonal().sum() == -3:\n",
    "            return -1\n",
    "        elif len(self.unassigned) == 0:\n",
    "            return 2  # draw\n",
    "        else: # ongoing\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, role='first', policy='random'):\n",
    "        self.role = role\n",
    "        self.policy = policy\n",
    "        self.state_values = {}\n",
    "\n",
    "    def move(self, board):\n",
    "        if self.policy == 'state_value':\n",
    "            x, y = self.best_move_by_state_value( board )\n",
    "        else: #if self.policy == 'random':\n",
    "            x, y = rnd.choice( tuple(board.unassigned) ) # return position\n",
    "        if self.role=='first':\n",
    "            board.add_X( x, y )\n",
    "        else: # role == 'later'\n",
    "            board.add_O( x, y )\n",
    "    \n",
    "    def set_state_values(self, board, value):\n",
    "        key = board.state.tostring()\n",
    "        self.state_values[ key ] = value\n",
    "    \n",
    "    def get_state_value(self, board):\n",
    "        key = board.state.tostring()\n",
    "        if  key not in self.state_values:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return self.state_values[ key ]\n",
    "    \n",
    "    # simulate next move\n",
    "    def best_move_by_state_value(self, board):\n",
    "        cand = [] # tuple ((x,y), state_value)\n",
    "        for x, y in board.unassigned:\n",
    "            # simulate move\n",
    "            if self.role == 'first':\n",
    "                board.add_X(x, y)\n",
    "            else: # role == 'later'\n",
    "                board.add_O(x, y)\n",
    "            tup = ((x,y), self.get_state_value(board))\n",
    "            #print tup    \n",
    "            cand.append( tup )\n",
    "            board.clear_pos(x, y) # revert !!\n",
    "        #print cand\n",
    "        tup_max = max( cand, key=lambda tup: tup[1])  # the tuple with max state value\n",
    "        pos = [ tup[0] for tup in cand if tup[1] == tup_max[1] ] # list of positions\n",
    "        #print pos\n",
    "        return rnd.choice( pos )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_board(self, board):\n",
    "        self.board = board;\n",
    "        \n",
    "    def set_agent_first(self, agent):\n",
    "        self.agent_first = agent\n",
    "    \n",
    "    def set_agent_later(self, agent):\n",
    "        self.agent_later = agent\n",
    "    \n",
    "    # return: 0: ongoing, 1: first wins, -1, later wins, 2: draw\n",
    "    def check_finish(self):\n",
    "        if_win = self.board.if_win()\n",
    "        return if_win\n",
    "    \n",
    "    def print_result(self, if_win):\n",
    "        if if_win == 0:\n",
    "            print 'game is ongoing...'\n",
    "        elif if_win == 1:\n",
    "            print 'Player First Wins!'\n",
    "        elif if_win == -1:\n",
    "            print 'Player Later Wins!'\n",
    "        else: #if_win == 2:\n",
    "            print 'Draw!'\n",
    "\n",
    "    # play a game (an episode)\n",
    "    # return: game result        \n",
    "    def auto_play(self, verbose=True):\n",
    "        self.board.reset()\n",
    "        if_win = 0 \n",
    "        while 1:\n",
    "            # first agent\n",
    "            self.agent_first.move( self.board )\n",
    "            if_win = self.check_finish()\n",
    "            if verbose:\n",
    "                self.board.print_board()\n",
    "                self.print_result( if_win )\n",
    "            if if_win != 0: # game over\n",
    "                break\n",
    "            # later agent    \n",
    "            self.agent_later.move( self.board )\n",
    "            if_win = self.check_finish()\n",
    "            if verbose:\n",
    "                self.board.print_board()\n",
    "                self.print_result( if_win )\n",
    "            if if_win != 0:\n",
    "                break\n",
    "        return if_win        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QTrainer(Game):\n",
    "    def __init__(self):\n",
    "        self.alpha = 1.0\n",
    "        self.gamma = 0.9\n",
    "    \n",
    "    # a TD learning method\n",
    "    # V(s) = V(s) + a * (R + g * V(s') - V(s))\n",
    "    def train_episode(self, verbose=False):\n",
    "        self.board.reset()\n",
    "        if_win = 0 \n",
    "        value_old = None \n",
    "        while 1:\n",
    "            ## first agent\n",
    "            self.agent_first.move( self.board )\n",
    "            if_win = self.check_finish()\n",
    "            if verbose:\n",
    "                self.board.print_board()\n",
    "                self.print_result( if_win )\n",
    "            if if_win == 1: # win\n",
    "                value_new = 1.0                \n",
    "            elif if_win == 2: # draw\n",
    "                value_new = -1.0\n",
    "            else:\n",
    "                value_new = self.agent_first.get_state_value( self.board )\n",
    "            self.agent_first.set_state_values( self.board, value_new )\n",
    "            # update last state value\n",
    "            if value_old != None:  \n",
    "                value_old += self.alpha * ( 0 + self.gamma * value_new - value_old )\n",
    "                self.agent_first.set_state_values( board_old, value_old )\n",
    "            # save current board state as last state    \n",
    "            board_old = copy.deepcopy( self.board ) \n",
    "            value_old = value_new\n",
    "            if if_win != 0: # game over\n",
    "                break\n",
    "                \n",
    "            ## later agent    \n",
    "            self.agent_later.move( self.board )\n",
    "            if_win = self.check_finish()\n",
    "            if verbose:\n",
    "                self.board.print_board()\n",
    "                self.print_result( if_win )\n",
    "            if if_win != 0: # later agent wins\n",
    "                # update last state value (for first agent)\n",
    "                value_old = -1.0\n",
    "                self.agent_first.set_state_values( board_old, value_old )\n",
    "                break\n",
    "        return if_win        \n",
    "    \n",
    "    # Can be called repeatedly to update agent's \"state_values\" function \n",
    "    def train(self, n_episode):\n",
    "        win_first = 0\n",
    "        win_later = 0\n",
    "        draw = 0\n",
    "        for i in range(n_episode):\n",
    "            rslt = self.train_episode(verbose=False)\n",
    "            if rslt == 1:\n",
    "                win_first += 1\n",
    "            elif rslt == -1:\n",
    "                win_later += 1\n",
    "            elif rslt == 2:\n",
    "                draw += 1\n",
    "        print 'f-win', win_first, 'l-win', win_later, 'draw', draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent_first = Agent('first', 'state_value')\n",
    "agent_later = Agent('later', 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print agent_first.state_values\n",
    "print agent_later.state_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = QTrainer()\n",
    "trainer.set_board( Board(3) )\n",
    "trainer.set_agent_first(agent_first)\n",
    "trainer.set_agent_later(agent_later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f-win 987121 l-win 53 draw 12826\n"
     ]
    }
   ],
   "source": [
    "trainer.train(1000000)\n",
    "np.save('agent_first_state_values_1M.npy', agent_first.state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -0.81, -1.0, 0.9, 1.0, 0.9, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -0.7290000000000001, -1.0, -0.7290000000000002, 1.0, 1.0, -1.0, -1.0, 0.81, 1.0, -0.9, 0.9, -1.0, -0.9, 1.0, -0.8099999999999999, 0.0, -0.81, 0.9, 1.0, -1.0, -1.0, -0.81, 0.0, -1.0, -0.81, 0.9, -1.0, -1.0, 0.9, -0.81, -0.9, -0.9, -1.0, -0.7290000000000002, -0.81, 0.9, 0.9, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.0, 1.0, -0.81, 1.0, 0.9, -1.0, -1.0, -1.0, -1.0, 0.9, 1.0, -1.0, -1.0, 0.9, -0.81, -1.0, -1.0, 1.0, -0.81, 0.0, -0.81, -0.81, 0.9, -1.0, -1.0, -1.0, -0.9, 0.0, 1.0, -0.81, 0.9, -1.0, 1.0, -0.9, -0.7290000000000001, 1.0, -0.7290000000000002, -1.0, -1.0, -0.8099999999999999, -0.9, -1.0, -0.9, 0.9, 1.0, 1.0, -0.8099999999999999, 0.9, 0.7290000000000001, 1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 0.81, -1.0, 1.0, 0.8999999999999999, 0.0, -1.0, 0.9, -0.7290000000000002, -1.0, 0.9, 0.81, 1.0, -0.9, 0.8999999999999999, -0.9, -1.0, -1.0, -1.0, 0.81, 0.0, -0.9, 0.81, -1.0, -0.7290000000000001, 0.9, -1.0, -1.0, 0.0, 1.0, -0.9, 0.9, -1.0, 1.0, -1.0, -0.81, -1.0, -1.0, -1.0, 1.0, 1.0, 0.9, 0.81, -1.0, 0.9, -1.0, -0.9, 1.0, 1.0, 0.7290000000000001, -1.0, -0.7290000000000001, 1.0, 0.9, 0.9, 0.0, -0.6561000000000002, 0.0, 0.9, -1.0, 0.9, 0.9, 1.0, -0.9, -0.9, 1.0, -1.0, 0.81, 1.0, -1.0, 0.0, -0.81, 1.0, -0.81, 0.7290000000000001, -1.0, 0.9, -0.81, -0.81, 0.0, 1.0, 0.9, 0.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.81, -1.0, -0.9, 0.9, 0.81, -0.81, -0.8099999999999999, 0.9, 1.0, 0.81, 0.9, -0.9, 1.0, -1.0, 0.9, -1.0, -1.0, -0.7290000000000002, -1.0, -0.81, -0.8099999999999999, -1.0, -0.9, 1.0, -0.9, -1.0, -0.9, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -0.9, 1.0, 1.0, 0.9, 1.0, -0.9, 1.0, 1.0, -0.8099999999999999, 1.0, -1.0, 1.0, 0.81, 0.9, -1.0, 0.9, -0.81, 0.7290000000000001, -0.9, -1.0, -0.9, 0.9, -1.0, 1.0, -1.0, -1.0, -1.0, 0.0, -0.9, -1.0, -0.7290000000000002, 0.9, -1.0, -0.81, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, -1.0, -1.0, -1.0, -1.0, 0.0, -0.9, 1.0, 0.9, 0.9, 1.0, -1.0, 0.9, 0.0, 0.8999999999999999, 0.9, 0.8999999999999999, -1.0, -0.9, -1.0, -1.0, -0.81, -1.0, -0.7290000000000002, -0.81, -0.81, -1.0, 1.0, -0.8099999999999999, -0.81, 1.0, 0.81, 1.0, -0.9, -0.9, -0.81, -0.81, -0.8099999999999999, -1.0, 0.9, -1.0, -0.81, 0.9, 1.0, -0.7290000000000001, -1.0, -0.9, -0.9, 1.0, -1.0, 0.9, 1.0, 0.9, 0.81, -0.81, 0.7290000000000001, 0.0, 1.0, 1.0, 0.9, -1.0, -1.0, -0.81, 0.0, 0.9, -0.7290000000000001, -0.81, -1.0, 0.0, 1.0, 0.9, 0.9, 1.0, 0.9, -0.9, -1.0, 1.0, -1.0, 0.9, -1.0, -0.81, -1.0, 0.9, -1.0, -1.0, 0.0, 0.9, -0.7290000000000001, -1.0, 0.9, -1.0, 1.0, 0.9, -1.0, -0.81, -0.81, -0.9, 1.0, -1.0, 1.0, 0.9, 0.0, 0.9, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -0.7290000000000001, -0.7290000000000002, 1.0, 1.0, 0.9, -1.0, 1.0, -0.9, 0.9, -0.7290000000000002, 1.0, 0.81, 0.0, -1.0, -1.0, 0.0, -0.81, 0.9, 1.0, 0.8999999999999999, -1.0, -0.9, 0.9, 0.8100000000000002, 1.0, -1.0, 0.0, 0.9, 0.0, 0.81, 0.81, 1.0, -0.9, -0.8099999999999999, -1.0, -0.8099999999999999, -0.9, -1.0, -1.0, -0.9, 1.0, -0.7290000000000002, 1.0, 0.81, -1.0, -1.0, 0.9, -1.0, 0.9, -0.9, -1.0, 1.0, 1.0, 1.0, -1.0, 0.9, 1.0, 1.0, 0.9, 0.9, -0.9, -1.0, 1.0, 0.0, 1.0, 1.0, 1.0, -0.9, -1.0, 0.9, 1.0, 1.0, -0.7290000000000001, 0.0, -0.81, -1.0, 0.9, -0.81, -0.81, -0.9, 1.0, 0.9, 0.9, -1.0, -1.0, 0.9, 0.0, -0.8099999999999999, -0.9, 0.8999999999999999, -0.9, 0.0, -0.9, -0.81, 0.0, 1.0, 0.9, 1.0, 0.9, 0.9, -0.7290000000000001, 0.0, -1.0, -0.81, -0.9, 0.81, 1.0, 0.9, -1.0, -0.81, 0.9, -0.9, -1.0, -0.9, -1.0, -1.0, 1.0, -0.81, 0.8999999999999999, -0.9, -1.0, -0.81, -1.0, 1.0, 0.9, 0.9, -1.0, -0.7290000000000001, -1.0, 0.9, -1.0, 0.0, -0.81, -0.7290000000000001, -0.9, 1.0, 0.9, 0.81, -1.0, -0.81, -1.0, 0.0, -0.8099999999999999, -1.0, -1.0, 0.9, -1.0, -1.0, -1.0, -0.8099999999999999, 1.0, -1.0, -0.9, 0.81, -1.0, -1.0, -0.9, -1.0, -0.9, -0.7290000000000001, 1.0, 0.9, -0.81, -0.81, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -0.9, 0.7290000000000001, 0.0, -0.7290000000000001, 0.81, 0.9, -1.0, -1.0, -0.9, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, 0.9, 1.0, 1.0, 0.9, 1.0, -0.9, 1.0, -1.0, -1.0, 1.0, 0.9, -1.0, 1.0, -0.81, -0.7290000000000001, -1.0, -0.9, -0.9, 1.0, -1.0, -1.0, 0.9, 1.0, -0.81, -0.7290000000000002, 1.0, 0.0, 0.0, -1.0, 1.0, 1.0, -0.9, -0.81, -1.0, 0.9, 1.0, 1.0, -1.0, 1.0, -0.8099999999999999, 0.9, 1.0, -1.0, -0.7290000000000002, -0.9, 1.0, -0.7290000000000001, -0.81, -1.0, -1.0, -0.8099999999999999, -0.9, -0.6561000000000003, 0.0, -1.0, 1.0, 1.0, 1.0, 0.9, 0.81, 1.0, -0.9, 0.9, 0.9, 0.9, 0.9, -1.0, -1.0, 0.9, 1.0, -1.0, 0.0, -0.81, -0.81, -0.9, 0.81, -0.7290000000000001, -1.0, -1.0, 0.9, -1.0, 1.0, 1.0, -1.0, -0.8099999999999999, 1.0, -0.9, 1.0, -0.9, 0.9, -1.0, 0.0, 0.0, -0.81, -0.7290000000000001, 0.9, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 0.0, -1.0, 0.0, 1.0, -1.0, -0.9, 1.0, -1.0, 0.0, -1.0, -1.0, -0.9, 1.0, 0.8999999999999999, 0.9, 1.0, -1.0, -1.0, -1.0, -0.9, -0.7290000000000001, 0.9, -0.9, 0.8999999999999999, -1.0, -1.0, -1.0, 1.0, 1.0, 0.9, 0.9, -1.0, -0.6561000000000001, -1.0, 1.0, 0.0, -0.8099999999999999, -1.0, 0.0, -1.0, 1.0, 0.9, 1.0, 1.0, 0.0, 0.0, 1.0, -0.7290000000000002, 1.0, -1.0, 1.0, -0.8099999999999999, 1.0, 0.9, -1.0, 0.81, 1.0, 0.0, -0.8099999999999999, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -0.7290000000000001, -1.0, 0.0, -1.0, -0.81, 1.0, -0.81, -0.81, 0.9, 0.0, -1.0, -0.9, -0.8999999999999999, -0.7290000000000001, 1.0, 1.0, 0.9, -0.9, -0.7290000000000001, -1.0, 0.81, 1.0, 0.81, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 0.9, 1.0, -1.0, -1.0, 1.0, -1.0, 0.9, -1.0, -1.0, 1.0, 0.9, 0.9, -0.9, -0.7290000000000001, -0.9, 0.9, 1.0, -0.8099999999999999, 1.0, -0.81, 0.9, -1.0, -0.9, 0.81, 1.0, 1.0, -1.0, 1.0, 1.0, -0.9, 1.0, 0.9, 1.0, 1.0, 1.0, -1.0, -1.0, 0.9, -0.9, 0.9, 0.9, -0.9, 0.8100000000000002, -0.9, 0.8999999999999999, -0.9, -1.0, 1.0, -0.9, -1.0, 0.9, 0.9, -1.0, 0.81, 1.0, -0.7290000000000001, 0.9, 1.0, -0.9, 0.0, -0.9, 0.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, -0.81, 1.0, 0.9, -1.0, -0.81, -0.9, -0.9, -1.0, -1.0, -0.9, -1.0, -1.0, -1.0, -1.0, -0.9, 1.0, -0.9, 1.0, 0.0, -1.0, 1.0, 0.9, -0.6561000000000002, 1.0, 0.0, -1.0, -0.9, 1.0, 0.9, -0.8099999999999999, 1.0, -1.0, -0.9, 0.9, 0.9, -1.0, 0.9, -1.0, -0.9, 1.0, -1.0, -1.0, 1.0, 1.0, 0.9, 1.0, -1.0, 1.0, -1.0, -1.0, 0.81, -1.0, -1.0, -0.7290000000000001, -0.81, -0.81, 1.0, 0.9, 0.9, -1.0, -1.0, 0.9, 0.9, -0.8099999999999999, -1.0, 1.0, 0.8100000000000002, 0.9, 0.9, 1.0, 0.9, -1.0, -0.81, 0.9, 1.0, 0.7290000000000001, -0.9, -0.7290000000000002, -1.0, -1.0, 0.9, -1.0, -1.0, 0.0, 0.81, 0.9, 0.9, -1.0, -0.81, 0.9, 1.0, 0.9, 0.0, -1.0, 0.9, -0.81, -0.8999999999999999, -0.9, 0.9, 1.0, 1.0, -0.8099999999999999, -1.0, 1.0, -1.0, -0.81, -1.0, -1.0, -0.81, -1.0, -0.81, -1.0, 0.0, 1.0, -0.9, 1.0, 1.0, 0.0, 0.9, -0.9, 0.0, 1.0, -1.0, 0.81, -0.7290000000000002, -0.81, 0.9, -1.0, -0.7290000000000002, -1.0, -1.0, -0.7290000000000001, 1.0, -1.0, 0.9, -0.8099999999999999, -1.0, -1.0, 0.9, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -0.9, 1.0, -0.9, 1.0, -1.0, 1.0, 1.0, -0.81, 0.9, 0.9, -1.0, 0.9, 0.9, -0.9, -1.0, 1.0, 1.0, 0.9, -1.0, -0.9, 0.0, -0.9, -1.0, 1.0, -1.0, -1.0, 0.0, -0.81, -0.7290000000000001, 0.0, 1.0, -1.0, -1.0, 1.0, -0.9, -1.0, -0.9, 1.0, 1.0, -1.0, 0.0, -1.0, 0.9, -0.81, 1.0, -1.0, 0.9, 1.0, -1.0, 0.9, -1.0, 0.9, -0.9, -0.81, 0.0, 0.9, 0.81, -1.0, -1.0, -0.81, -1.0, 0.9, 1.0, 0.0, 0.9, 0.0, 0.9, 1.0, -0.9, 1.0, 0.8999999999999999, 0.9, 1.0, -0.9, -0.9, 1.0, 0.9, -1.0, -1.0, -1.0, -1.0, 1.0, -0.9, -1.0, 0.9, -1.0, 0.0, -0.9, 0.0, 0.9, 0.0, 1.0, -0.9, 1.0, 0.8999999999999999, -1.0, -0.81, -1.0, 0.9, -0.8099999999999999, 0.0, -1.0, -0.7290000000000002, -1.0, -0.9, -1.0, 0.9, 1.0, -1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.9, -1.0, 0.0, -1.0, -1.0, 0.0, 1.0, -0.9, 1.0, 1.0, 0.9, -1.0, -1.0, -1.0, -0.81, -1.0, -0.9, 0.9, 1.0, -1.0, 0.81, 1.0, -0.7290000000000001, 1.0, 1.0, -1.0, -1.0, 0.81, -1.0, -0.7290000000000002, -1.0, 1.0, -1.0, -0.8099999999999999, -1.0, -1.0, 0.81, -1.0, 0.9, -0.9, 1.0, -1.0, 0.9, -0.9, -1.0, -0.8099999999999999, 0.9, 1.0, -1.0, -1.0, -1.0, -0.9, -0.9, -0.7290000000000001, -0.81, -1.0, -1.0, -1.0, -0.7290000000000001, 0.0, -0.81, -1.0, 0.9, 1.0, 0.9, -0.9, -1.0, -0.9, 0.0, -0.7290000000000001, -1.0, 0.9, -0.8099999999999999, 0.0, -1.0, 1.0, 1.0, -0.81, 1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 0.0, -0.9, 0.9, 1.0, -1.0, 1.0, -1.0, -0.9, -1.0, -1.0, 0.9, -1.0, 0.81, -1.0, 0.81, 1.0, -1.0, 0.9, -0.81, 0.9, -1.0, 0.81, 1.0, -1.0, 0.0, 0.0, -0.81, 0.9, -1.0, -0.81, -1.0, 1.0, -1.0, -1.0, -0.8099999999999999, 0.9, -1.0, 0.9, 1.0, -0.9, -1.0, -0.7290000000000001, 1.0, 1.0, -1.0, -0.81, -0.81, -1.0, -1.0, -1.0, -0.9, 0.81, 0.9, 0.9, -1.0, 1.0, -0.9, -0.81, -1.0, -0.8099999999999999, -0.7290000000000001, -1.0, -0.9, -0.9, -0.9, 1.0, -1.0, -1.0, 1.0, -0.7290000000000001, -0.9, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 0.9, 0.81, -1.0, 0.81, -1.0, -0.9, 0.0, -1.0, 0.7290000000000002, 0.9, -0.9, -1.0, 0.0, -1.0, -0.9, 1.0, 1.0, -0.9, -1.0, -0.81, 0.9, 1.0, -1.0, 0.9, -0.9, 0.9, -1.0, -1.0, -1.0, 0.9, -1.0, 0.0, -0.8099999999999999, -0.81, -0.81, 0.81, -1.0, 1.0, -1.0, 1.0, -1.0, -0.7290000000000001, -1.0, -1.0, -0.81, -0.7290000000000001, 0.9, -1.0, 0.81, -1.0, 1.0, -1.0, -0.8099999999999999, 0.9, 1.0, -1.0, 1.0, 0.9, 0.0, 0.9, 1.0, -0.8099999999999999, 0.81, 0.9, 1.0, -1.0, -0.9, 0.9, -0.81, 1.0, 0.9, 1.0, 0.9, 0.0, 1.0, 0.0, -1.0, 1.0, 0.0, 1.0, -0.9, 1.0, -1.0, -1.0, 0.9, -0.7290000000000001, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -0.81, -0.81, 0.0, -0.9, -1.0, -1.0, -1.0, -0.9, -1.0, 1.0, 0.9, -0.81, 0.0, -1.0, -0.9, -0.81, -1.0, -1.0, 1.0, -1.0, 1.0, 0.9, 0.9, -0.81, 0.81, 0.9, 1.0, 1.0, 0.0, -1.0, 1.0, 0.9, -0.81, -1.0, 1.0, -1.0, -1.0, -0.7290000000000001, -1.0, 1.0, -1.0, 0.0, -0.9, 0.9, -1.0, 0.9, 0.9, 1.0, -1.0, 0.81, 0.81, 1.0, 1.0, 0.9, -0.7290000000000002, -1.0, 0.9, -0.81, 0.9, -1.0, -0.9, 1.0, 0.9, 1.0, -1.0, -0.9, 1.0, -0.9, -1.0, -1.0, 0.7290000000000001, -0.8099999999999999, 1.0, -0.81, -0.9, -1.0, 1.0, -0.9, -1.0, -0.9, -1.0, -0.81, 0.9, 1.0, 1.0, 1.0, -0.8099999999999999, 0.9, 1.0, -1.0, -1.0, 0.81, -1.0, 1.0, -0.7290000000000002, 0.9, 0.0, 0.9, 1.0, -0.9, 0.9, 1.0, 1.0, 0.9, -0.9, 1.0, -0.7290000000000001, 0.9, 0.9, -0.9, -0.9, 0.81, 0.9, 1.0, 1.0, -0.9, 1.0, 0.9, -1.0, 0.0, -1.0, -1.0, -1.0, -1.0, 1.0, 0.9, -1.0, 0.0, -0.7290000000000001, -1.0, -1.0, -0.81, 0.81, 0.0, 1.0, -1.0, 0.9, 1.0, -0.7290000000000001, -0.9, 1.0, 1.0, -1.0, 0.9, 1.0, -1.0, 1.0, 1.0, 0.0, 0.9, -1.0, -1.0, -0.9, -0.9, -0.81, 1.0, 1.0, -0.8099999999999999, -1.0, 1.0, 0.9, 0.81, 1.0, -1.0, 1.0, 1.0, -1.0, 0.9, 1.0, 0.0, 0.9, 0.9, -1.0, -0.9, -0.9, -0.81, 0.81, -1.0, -1.0, -0.81, 1.0, -1.0, 0.9, -1.0, -0.9, -1.0, 1.0, -1.0, 1.0, 1.0, -0.81, 1.0, 0.9, -1.0, -0.81, -0.9, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.81, 0.9, 1.0, -0.7290000000000001, -0.7290000000000001, 1.0, -0.9, 0.81, 0.9, 0.9, 1.0, 0.9, -1.0, -1.0, -1.0, 1.0, -0.9, -1.0, 0.9, -1.0, 1.0, -1.0, 0.0, 0.0, -0.9, -0.7290000000000001, -0.8099999999999999, 0.9, 1.0, -1.0, -1.0, -0.729, -0.81, -0.9, -1.0, 0.9, -1.0, 0.9, -1.0, 1.0, 0.8999999999999999, -0.81, 0.9, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -0.81, -1.0, 0.9, 0.0, -0.8099999999999999, 0.9, -1.0, -0.7290000000000002, 0.9, -1.0, 1.0, -0.9, -1.0, -1.0, 0.0, 0.9, 1.0, 0.9, -1.0, 1.0, 1.0, 0.0, -1.0, 1.0, -1.0, -1.0, -0.9, -0.8099999999999999, 1.0, -0.81, -1.0, 1.0, 0.9, 0.9, -1.0, -1.0, -1.0, 1.0, -1.0, -0.81, -1.0, -0.81, 0.8999999999999999, -0.7290000000000002, 0.9, -1.0, -0.81, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8100000000000002, 0.9, -1.0, 0.81, 0.9, -1.0, -1.0, 0.81, 0.9, 0.0, -1.0, 1.0, -1.0, -1.0, -1.0, 1.0, 0.9, -0.9, -1.0, 1.0, -1.0, 0.81, 0.0, -1.0, 1.0, 0.9, -1.0, -1.0, 1.0, -0.9, 0.9, 1.0, -1.0, 0.81, 0.0, 1.0, -1.0, 0.0, -1.0, 1.0, 0.9, 0.81, -0.9, 1.0, -1.0, -0.81, -1.0, 0.81, 1.0, 0.9, -1.0, -0.9, -0.81, -1.0, 0.81, 0.9, -1.0, -0.9, -0.7290000000000001, 1.0, -0.8099999999999999, 1.0, 0.9, -0.9, -1.0, -0.9, -0.7290000000000001, -0.9, 1.0, -0.9, -1.0, -1.0, 1.0, 0.9, -1.0, 0.9, -1.0, -0.6561000000000001, 0.0, 1.0, 0.9, 1.0, -1.0, 1.0, -0.9, 1.0, -0.9, -1.0, 1.0, -1.0, 1.0, 0.9, 0.9, -1.0, 1.0, 0.8999999999999999, 1.0, -0.81, -1.0, -1.0, -0.9, 0.9, 0.0, 1.0, -1.0, -0.9, 1.0, 0.9, 1.0, -1.0, 1.0, 1.0, -0.9, 1.0, -0.9, 1.0, -0.81, 0.9, 1.0, -1.0, 0.0, 0.9, 0.7290000000000001, -0.7290000000000002, -1.0, 1.0, 0.0, 0.81, 1.0, -1.0, 1.0, -0.9, 0.8999999999999999, 1.0, 1.0, -1.0, -0.8099999999999999, -1.0, 1.0, 1.0, 0.81, 0.9, 1.0, 0.0, 1.0, -1.0, -1.0, -0.81, -0.7290000000000002, -1.0, -0.9, 1.0, -0.8099999999999999, -0.9, -1.0, -0.81, 1.0, -1.0, -0.81, -0.9, -1.0, 0.9, 1.0, 1.0, -1.0, 0.9, 0.0, 0.9, -1.0, 1.0, -0.9, -1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 0.0, 1.0, -1.0, -0.9, 0.81, -0.81, 0.9, -0.9, 1.0, -1.0, 0.9, -1.0, 1.0, -1.0, 0.9, -0.81, 0.9, 0.9, 0.9, -1.0, -0.9, -0.8099999999999999, 0.9, -0.7290000000000001, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 0.9, 1.0, -0.81, 1.0, 0.0, -1.0, -0.7290000000000001, -1.0, 1.0, -0.9, 1.0, 1.0, -0.9, 0.9, -0.9, 0.9, 1.0, 0.9, -1.0, 1.0, 1.0, -1.0, 0.9, -1.0, 0.0, -0.81, -1.0, -0.9, 1.0, -0.9, -1.0, 0.0, 0.0, -1.0, 1.0, -0.8099999999999999, -1.0, -1.0, -0.9, 1.0, -1.0, 1.0, -0.9, 0.0, 0.9, 0.9, -1.0, -1.0, 0.9, 1.0, -1.0, 1.0, -0.7290000000000002, -1.0, 1.0, 0.8999999999999999, -0.8099999999999999, -1.0, 1.0, 0.0, 0.7290000000000001, -1.0, -1.0, -1.0, 1.0, -0.9, -0.9, -1.0, 0.9, 1.0, -0.9, -0.81, -0.9, -1.0, -0.9, 1.0, -1.0, -0.8099999999999999, 1.0, 0.0, 1.0, 1.0, -0.9, 1.0, -1.0, -1.0, 1.0, -1.0, 0.9, -0.9, -1.0, 0.0, -1.0, 1.0, 0.0, -0.8099999999999999, -0.9, 1.0, -1.0, 0.9, -1.0, -0.81, 1.0, 0.81, -0.7290000000000002, -0.9, -1.0, -1.0, -1.0, 1.0, -0.8099999999999999, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -0.9, 0.9, -1.0, 0.9, -1.0, -0.9, -0.81, 1.0, -1.0, -1.0, -1.0, -0.81, -0.9, 0.9, -1.0, 1.0, 0.81, -0.7290000000000001, -1.0, 0.81, 0.81, -1.0, 0.9, -1.0, -0.9, 0.8999999999999999, 0.9, -0.9, 1.0, -0.8099999999999999, -0.8099999999999999, 0.81, 1.0, 0.9, -1.0, -1.0, -1.0, -1.0, -1.0, -0.9, -1.0, 0.9, -0.9, 0.9, 0.9, -1.0, 0.9, 0.9, -1.0, -1.0, -0.8099999999999999, 0.81, 1.0, -0.7290000000000001, 1.0, -1.0, 0.0, -0.7290000000000002, -1.0, 1.0, 1.0, 1.0, 0.9, -1.0, -1.0, 0.9, 1.0, 0.9, -0.8999999999999999, -1.0, 1.0, 0.9, -0.9, 1.0, -0.81, 1.0, -1.0, 1.0, 1.0, 0.0, -0.9, -0.9, -1.0, 0.0, 0.81, -0.9, -1.0, -0.7290000000000002, 0.0, -1.0, -0.81, -0.81, -1.0, 0.9, 0.9, -0.9, -1.0, 1.0, 0.9, -0.7290000000000001, 1.0, -0.9, 0.9, 1.0, -1.0, -1.0, -1.0, 0.9, 0.0, 0.9, 1.0, -1.0, 0.9, 1.0, 0.81, -0.9, 0.9, -1.0, 0.0, 1.0, 0.9, 1.0, 0.9, 0.0, -1.0, 1.0, -0.9, -1.0, -0.6561000000000003, -0.81, -1.0, 0.9, -1.0, 0.0, -0.8099999999999999, -0.81, -0.729, -1.0, 0.8999999999999999, -0.8099999999999999, -0.8099999999999999, 1.0, 1.0, -1.0, -1.0, 0.0, 1.0, 1.0, -0.7290000000000001, 1.0, 1.0, -1.0, -1.0, 1.0, 0.81, 0.9, -0.81, -0.9, -1.0, 0.9, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 0.0, 1.0, -1.0, 1.0, -0.81, -0.7290000000000002, 1.0, -1.0, -1.0, -0.9, -1.0, 0.9, -0.81, -0.7290000000000002, -0.9, -0.9, 0.0, 0.0, 1.0, -0.81, -1.0, -1.0, 0.9, -1.0, 0.0, 0.9, -1.0, 0.81, 0.9, 1.0, 0.8100000000000002, -0.81, -1.0, -1.0, 1.0, -1.0, 0.9, -1.0, -0.7290000000000002, 0.0, 0.0, 1.0, -0.81, -1.0, 1.0, -1.0, -0.9, -1.0, 0.9, -0.7290000000000002, -0.7290000000000002, -1.0, 1.0, -0.7290000000000001, -0.9, 0.81, 0.0, -1.0, 0.9, -0.9, 1.0, 1.0, -0.6561000000000003, 1.0, 1.0, -1.0, 0.9, -0.9, -0.9, -0.7290000000000002, -1.0, -1.0, -1.0, -0.9, 0.9, 1.0, -1.0, -1.0, -0.9, -1.0, 0.9, 0.81, 0.9, 1.0, -0.729, -1.0, -0.9, -0.7290000000000002, -0.81, 1.0, 0.81, 1.0, 0.9, 1.0, 0.81, 1.0, -1.0, 1.0, -0.9, 1.0, -0.8099999999999999, 0.9, -0.81, -0.9, -1.0, -0.9, -0.9, 0.0, -0.7290000000000001, 1.0, -1.0, -0.81, -0.81, 1.0, 1.0, -1.0, 0.0, -1.0, -0.9, -1.0, -0.6561000000000001, -1.0, 1.0, -0.7290000000000001, 1.0, -1.0, -1.0, 1.0, 0.9, -0.9, 1.0, -1.0, -1.0, -1.0, -0.729, 1.0, -0.81, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 0.9, 0.9, 0.9, 1.0, -0.8999999999999999, -1.0, 1.0, -0.7290000000000002, -1.0, 0.9, -0.9, -0.81, 1.0, -1.0, 0.0, -1.0, -1.0, 0.0, 0.9, 0.0, -0.9, -0.9, 0.0, -0.9, 1.0, -0.8099999999999999, 1.0, -1.0, 0.9, 1.0, -0.8099999999999999, 1.0, -1.0, -1.0, 0.9, -0.8099999999999999, -0.81, -0.9, -1.0, 0.9, 0.81, -0.9, 0.0, -1.0, -0.8099999999999999, 0.9, -0.9, -0.9, 1.0, 1.0, -1.0, -1.0, 1.0, -0.81, -0.9, 1.0, -1.0, 1.0, -0.7290000000000002, 0.0, -0.81, -1.0, 0.0, 0.9, -1.0, 0.9, 1.0, -1.0, 0.9, 0.8999999999999999, 0.9, 1.0, 0.9, -0.9, 0.9, -1.0, -0.9, -1.0, -1.0, -0.9, 1.0, 0.9, 1.0, -0.9, -0.81, 1.0, 1.0, 0.0, -0.7290000000000001, 1.0, -0.9, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print agent_first.state_values.values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = Game()\n",
    "game.set_board( Board(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game.set_agent_first( agent_first )\n",
    "game.set_agent_later( agent_later )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngame.set_agent_first( Agent('first', 'random') )\\ngame.set_agent_later( Agent('later', 'random') )\\n\""
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "game.set_agent_first( Agent('first', 'random') )\n",
    "game.set_agent_later( Agent('later', 'random') )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9939 0 61\n"
     ]
    }
   ],
   "source": [
    "win_first = 0\n",
    "win_later = 0\n",
    "draw = 0\n",
    "for i in range(10000):\n",
    "    rslt = game.auto_play(verbose=False)\n",
    "    if rslt == 1:\n",
    "        win_first += 1\n",
    "    elif rslt == -1:\n",
    "        win_later += 1\n",
    "    elif rslt == 2:\n",
    "        draw += 1\n",
    "print win_first, win_later, draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
